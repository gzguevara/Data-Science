{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2PD4quI33zf"
      },
      "source": [
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()\n",
        "\n",
        "import scipy.io\n",
        "from fastbook import *\n",
        "from fastai.vision.widgets import *\n",
        "from fastai.text.all import *\n",
        "from fastai import * \n",
        "from fastai.text import * "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akALo_5G-lIC"
      },
      "source": [
        "path     = untar_data('https://s3.amazonaws.com/fast-ai-nlp/yelp_review_full_csv.tgz')\n",
        "Path.BASE_PATH = path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJiFjBKVKUEv"
      },
      "source": [
        "I will do this homework with 1000 datapoints as otherwise, even with GPU, it does not work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxkMt0HGAwvo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b1c1f4c-91cf-4dcd-ce13-f8b5d34e55fe"
      },
      "source": [
        "data = pd.read_csv((path/'train.csv'), names = ['label', 'text'])\n",
        "data = data.drop(list(range(1,649001)))\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruoQJ7DKMZzY"
      },
      "source": [
        "Loading the data into batches of size 65 with length of sequencce 72"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLDZjIAIX5oL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "d25a3946-a2f9-42a4-9ca1-c8de33f43cf6"
      },
      "source": [
        "imdb_lm = DataBlock(blocks   = TextBlock.from_df('text', is_lm=True),\n",
        "                    get_x    = ColReader('text'),\n",
        "                    splitter = RandomSplitter(0.1))\n",
        "\n",
        "dls = imdb_lm.dataloaders(data, bs=64, seq_len=72)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KruXJHxh99ec"
      },
      "source": [
        "Here we can see all the features which are automatically handled by fastai like tokenization. This is relevant for the algorithm as it ensures an efficient differentiation between the words and therefore allows to weigh certain words more than others"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "ip2mkrEnMtAN",
        "outputId": "d82a5468-3b04-4cae-f0ba-08a3bc8360c6"
      },
      "source": [
        "dls.show_batch(max_n=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xxbos xxmaj nice .. casual .. great service ( vegas great ) .. \\n xxmaj east access .. sweet setting .. cool people . xxunk music .. and off course .. great looking service xxbos xxmaj this is cool place to eat . xxmaj great atmosphere and good food . xxmaj good people . xxmaj food has been great every time i go . xxbos xxmaj xxunk made a xxup great xxup</td>\n",
              "      <td>xxmaj nice .. casual .. great service ( vegas great ) .. \\n xxmaj east access .. sweet setting .. cool people . xxunk music .. and off course .. great looking service xxbos xxmaj this is cool place to eat . xxmaj great atmosphere and good food . xxmaj good people . xxmaj food has been great every time i go . xxbos xxmaj xxunk made a xxup great xxup cocktail</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>her friend 's birthday party . xxmaj it worked out very well . xxmaj the group picked out the pieces they wanted to do , xxunk and chatted away for about an hour , cleaned up together , and then finished with gifts and a xxunk of \" happy xxmaj birthday to xxmaj you \" . xxmaj it was superb to have kids and parents playing + working together for an activity</td>\n",
              "      <td>friend 's birthday party . xxmaj it worked out very well . xxmaj the group picked out the pieces they wanted to do , xxunk and chatted away for about an hour , cleaned up together , and then finished with gifts and a xxunk of \" happy xxmaj birthday to xxmaj you \" . xxmaj it was superb to have kids and parents playing + working together for an activity for</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WNLY0zFM2oy"
      },
      "source": [
        "Building the model as in the book"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7DeP_KnYiA6"
      },
      "source": [
        "learn = language_model_learner(dls, AWD_LSTM, drop_mult=0.3, metrics=[accuracy, Perplexity()]).to_fp16()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFT8BjBFNj1i"
      },
      "source": [
        "fit a few epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "FhT4WkvGNSH7",
        "outputId": "33a8626f-3e7a-426d-bf6d-bad3696f2dc5"
      },
      "source": [
        "learn.fit_one_cycle(5, 2e-3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.734847</td>\n",
              "      <td>4.590147</td>\n",
              "      <td>0.226531</td>\n",
              "      <td>98.508865</td>\n",
              "      <td>00:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.515180</td>\n",
              "      <td>4.328839</td>\n",
              "      <td>0.246579</td>\n",
              "      <td>75.856186</td>\n",
              "      <td>00:23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4.328253</td>\n",
              "      <td>4.218273</td>\n",
              "      <td>0.251687</td>\n",
              "      <td>67.916107</td>\n",
              "      <td>00:23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4.191616</td>\n",
              "      <td>4.174661</td>\n",
              "      <td>0.252590</td>\n",
              "      <td>65.017807</td>\n",
              "      <td>00:23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>4.114514</td>\n",
              "      <td>4.167120</td>\n",
              "      <td>0.252284</td>\n",
              "      <td>64.529305</td>\n",
              "      <td>00:23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9pcDeyiG6Oi"
      },
      "source": [
        "learn.save_encoder('fine_tuned')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-D-BoONv3dQ"
      },
      "source": [
        "Here are the generations of text. I used the word \"moscow\" just for fun. However as those are reviews from america about restaurants, it probablu does not reallt now wgat to to with \"moscow\". However, the word \"moscow\" must have been among the 1000 messages I used, as the\n",
        " algorithm is able to recocnize it!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "lCXgWSHeFjlp",
        "outputId": "f312207a-55d7-4d93-fdbf-e39f5c7e98fe"
      },
      "source": [
        "[learn.predict(\"The people in Moscow\", n_words = 10, temperature=0.75) for _ in range(5)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The people in Moscow are women , and Vietnamese women have been involved',\n",
              " 'The people in Moscow together , including Steve Wynn and Billy',\n",
              " 'The people in Moscow have a similar response to the First People',\n",
              " 'The people in Moscow are Japanese - speaking people , who are',\n",
              " 'The people in Moscow during the Cold \" Day \"']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6Vp1760B8rO"
      },
      "source": [
        "This is somehow more logical, but still not good. However, more using more than 1000 should resolve this problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "k-wQYzshB4A5",
        "outputId": "3ca1d8b6-f01c-4e44-feb1-6a2cbad8035d"
      },
      "source": [
        "[learn.predict(\"The restaurant\", n_words = 15, temperature=0.75) for _ in range(5)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The restaurant is open to the public on weekends and is open on Friday .',\n",
              " 'The restaurant in Las Vegas , Las Vegas , is known as the',\n",
              " 'The restaurant that Expensive Taste was supposed to host was the House of',\n",
              " 'The restaurant was opened with a restaurant on the same day as The Restaurant .',\n",
              " 'The restaurant in Dallas , Texas is located close to the Dallas Wings']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ofm3AMRnCTTv"
      },
      "source": [
        "Now I build the data block for the classification problem with the necessary vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "eRFfdw-yGfrC",
        "outputId": "5cd357fd-e925-4395-e547-a96affd13135"
      },
      "source": [
        "imdb_clas = DataBlock(blocks=(TextBlock.from_df('text', seq_len=72, vocab=dls.vocab), CategoryBlock),\n",
        "                      get_x    = ColReader('text'),\n",
        "                      get_y    = ColReader('label'),\n",
        "                      splitter = RandomSplitter(0.1))\n",
        "\n",
        "dls = imdb_clas.dataloaders(data, bs=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHavwv3zGxJf"
      },
      "source": [
        "learn_new = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy).to_fp16()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLLIbhyoGzLK"
      },
      "source": [
        "learn_new = learn_new.load_encoder('fine_tuned')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddaWQinxCd9G"
      },
      "source": [
        "And the results are not very good. haha. But one should be able to improve this with more observations as I said."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "FF82bMy7HT4q",
        "outputId": "91ffe392-8cd0-42c1-97aa-4c6c0faa2a0b"
      },
      "source": [
        "learn_new.show_results(max_n=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>category_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xxbos xxmaj why ? xxmaj why ? xxmaj why … can we not get more solid xxup bbq here ? xxmaj has xxmaj vegas been xxunk by some sort of barbecue xxunk xxunk ? xxmaj have the xxup bbq xxmaj xxunk no xxunk on xxmaj sin xxmaj city ? i really just do n't get it . xxmaj but before i self - xxunk , let me explain … \\n\\n xxmaj bubba xxmaj d 's is a brand new xxup bbq joint located inside the xxmaj town xxmaj center xxmaj lounge on xxmaj xxunk xxmaj xxunk , just off xxmaj xxunk &amp; the xxunk . xxmaj i 'm not super familiar with this lounge , but i do know from driving by it everyday that the restaurant inside has seen its fair share of changes . xxmaj not long ago , a breakfast place used to be here that i</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>xxbos xxmaj first , let me say , i am so happy to have xxmaj culinary xxmaj dropout open in xxmaj tempe in the xxmaj farmer xxmaj xxunk xxmaj district . i think it is going to be an xxunk establishment for lots of other development in this area and talk about a well run establishment , wow , one can almost hear the xxunk of xxunk efficiency in how this place is run and it is a big space and so popular ! i took my work - team to lunch here today and honestly , no detail is xxunk and i have no doubt that in going here folks will have a consistently positive experience . \\n\\n xxmaj as for why it is only marked as a - ok right now - well , my first time at this location and as with the other culinary dropout i</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "FU6ZQkwGHY9w",
        "outputId": "4873cc87-f201-44a6-f2eb-e27dbec839d2"
      },
      "source": [
        "interp = ClassificationInterpretation.from_learner(learn_new)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "L_S5d-rwN5YD",
        "outputId": "79833a7d-93ad-46b0-87a0-0117c7859b11"
      },
      "source": [
        "interp.plot_top_losses(k=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>target</th>\n",
              "      <th>predicted</th>\n",
              "      <th>probability</th>\n",
              "      <th>loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xxbos xxmaj yelp xxunk you to xxunk xxup characters in your reviews -- which simply is not enough for things like \" experiences . \" xxmaj that said i have posted a full review here on our xxunk at xxunk : / / xxunk / 2014 / 12 / xxunk / our - experience - at - marvel - experience / for all to see complete with pictures if you would like more details about my comments below \\n\\n xxmaj xxunk : \\n xxmaj it should be xxunk that i xxunk from reading any reviews or watching any news xxunk about this event prior to our visit so i kept my own expectations as high as they should have been for the cost of the tickets . xxmaj also , while some may say it is not fair to compare something like this to \" disneyland \" , i disagree</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.23139896988868713</td>\n",
              "      <td>1.7064099311828613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>xxbos i always xxunk at the xxunk of going to a restaurant that xxunk in nachos . i would hear xxunk of my friend who would xxunk xxmaj nacho xxmaj daddy on his side of town for hours on end . i was so close to going the one xxmaj downtown , however i was xxunk home xxunk by my significant other . \\n\\n xxmaj this time . xxmaj this time , it was xxup xxunk ! xxmaj my friends and i counted the days to opening when we first saw it was coming to our side of town . xxmaj the the time came . xxmaj we sat , we ate , we got full . xxmaj we left happy . \\n\\n xxmaj this place was awesome . xxmaj great ambiance . xxmaj awesome xxmaj servers . xxmaj insane menu ! xxmaj the prices may be a tiny bit</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.2272447943687439</td>\n",
              "      <td>1.7035293579101562</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khqsAvTCC6qu"
      },
      "source": [
        "When I tried to improve the model with freezing, the accuray actually improved already in the first epoach, compared to the previous approach!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "dYrv7ukL9toX",
        "outputId": "3101a311-0057-4c67-dcf7-62c787cd223f"
      },
      "source": [
        "learn.freeze_to(-3)\n",
        "learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.915854</td>\n",
              "      <td>3.954830</td>\n",
              "      <td>0.268000</td>\n",
              "      <td>52.186817</td>\n",
              "      <td>00:27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}