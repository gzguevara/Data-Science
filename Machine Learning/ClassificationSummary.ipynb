{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification** is a technique where we categorize data into a given number of classes. The main goal of a classification problem is to identify the category/class to which a new data will fall under. Classification is **supervised learning technique**.\n",
    "\n",
    "\n",
    "Terminology:\n",
    "- **Classifier**: an algorithm that maps the input data to a specific category.\n",
    "- **Classification model**: A classification model tries to draw some conclusion from the input values given for training. It will predict the class labels/categories for the new data.\n",
    "- **Feature**: A feature is an individual measurable property of a phenomenon being observed.\n",
    "\n",
    "There are different types of classification: **binary** (2 classes), **multi-class** (>2 classes) and **multi-label** (>1 classes are assigned to an object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, classification_report, accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification\n",
    "\n",
    "Let us look at data regarding coronary heart disease (CHD) in South Africa.\n",
    "The columns of the dataset:\n",
    "- **sbp**: systolic blood pressure\n",
    "- **tobacco**: cumulative tobacco (kg)\n",
    "- **ldl**: low densiity lipoprotein cholesterol\n",
    "- **adiposity**: severe or morbid overweight\n",
    "- **famhist**: family history of heart disease (Present - 1, Absent - 0)\n",
    "- **typea**: type-A behavior\n",
    "- **obesity**: abnormal or excessive fat accumulation\n",
    "- **alcohol**: current alcohol consumption\n",
    "- **age**: age at onset\n",
    "- **chd**: response, coronary heart disease ($target$ variable)\n",
    "\n",
    "*The goal* is to predict coronary heart desease (CHD) based on other attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbp</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>ldl</th>\n",
       "      <th>adiposity</th>\n",
       "      <th>famhist</th>\n",
       "      <th>typea</th>\n",
       "      <th>obesity</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>age</th>\n",
       "      <th>chd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row.names</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>160</td>\n",
       "      <td>12.00</td>\n",
       "      <td>5.73</td>\n",
       "      <td>23.11</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>25.30</td>\n",
       "      <td>97.20</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>144</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.41</td>\n",
       "      <td>28.61</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>28.87</td>\n",
       "      <td>2.06</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>118</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3.48</td>\n",
       "      <td>32.28</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>29.14</td>\n",
       "      <td>3.81</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170</td>\n",
       "      <td>7.50</td>\n",
       "      <td>6.41</td>\n",
       "      <td>38.03</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>31.99</td>\n",
       "      <td>24.26</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>134</td>\n",
       "      <td>13.60</td>\n",
       "      <td>3.50</td>\n",
       "      <td>27.78</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>25.99</td>\n",
       "      <td>57.34</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sbp  tobacco   ldl  adiposity  famhist  typea  obesity  alcohol  \\\n",
       "row.names                                                                    \n",
       "1          160    12.00  5.73      23.11        1     49    25.30    97.20   \n",
       "2          144     0.01  4.41      28.61        0     55    28.87     2.06   \n",
       "3          118     0.08  3.48      32.28        1     52    29.14     3.81   \n",
       "4          170     7.50  6.41      38.03        1     51    31.99    24.26   \n",
       "5          134    13.60  3.50      27.78        1     60    25.99    57.34   \n",
       "\n",
       "           age  chd  \n",
       "row.names            \n",
       "1           52    1  \n",
       "2           63    1  \n",
       "3           46    0  \n",
       "4           58    1  \n",
       "5           49    1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart = pd.read_csv(r'SAHeart.csv', sep=',', header=0, index_col=0)\n",
    "heart.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us calculate the total number of observations for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    302\n",
       "1    160\n",
       "Name: chd, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart.chd.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![balanced data](https://miro.medium.com/max/450/1*zsyN08VVrgHbAEdvv27Pyw.png \"Balanced And Imbalanced Datasets\")\n",
    "\n",
    "In general, if there are two classes, then *balanced data* would mean 50% points for each of the class. \n",
    "\n",
    "We can observe in our data that **65%** of people have no desease while **35%** of people have no desease. In our case there is a little imbalance in our data which should not cause any significant performance degradation. \n",
    "\n",
    "However, you should remember that **if the class imbalance is high** (e.g. 90% points for one class and 10% for the other), **standard optimization criteria or performance measures may not be as effective and would need modification**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us separates the data frame into a `y` vector of the response and an `X` matrix of explanatory variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = heart.iloc[:,9]\n",
    "X = heart.iloc[:,:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the steps involved in building a classification model:\n",
    "\n",
    "- **Initialize** the classifier to be used.\n",
    "- **Train** the classifier: All classifiers in scikit-learn uses a fit(X, y) method to fit the model(training) for the given train data X and train label y.\n",
    "- **Predict** the target: Given an unlabeled observation X, the predict(X) returns the predicted label y.\n",
    "- **Evaluate** the classifier model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic regression\n",
    "Logistic Regression is a type of Generalized Linear Model (GLM) that uses a logistic function to model a binary variable based on any kind of independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, multi_class='ovr', random_state=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr', max_iter=1000)\n",
    "LR.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions (probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the score (average accuracy) of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7359307359307359"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[256,  46],\n",
       "       [ 76,  84]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y, LR.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the F-score of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5793103448275863"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y, LR.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. K-Nearest Neighbours\n",
    "According to K-Nearest Neighbours algorithm, classification is computed from a simple majority vote of the k nearest neighbours of each point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy and F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.7207792207792207\n",
      "F-1 score is 0.5309090909090909\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is\", knn.score(X,y))\n",
    "print(\"F-1 score is\", f1_score(y, knn.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Decision Tree\n",
    "Given a data of attributes together with its classes, a decision tree produces a sequence of rules that can be used to classify the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5, min_samples_leaf=5, random_state=101)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier(max_depth = 5, random_state = 101, min_samples_leaf = 5)\n",
    "dtree.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.8116883116883117\n",
      "F-1 score is 0.6947368421052631\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is\", dtree.score(X,y))\n",
    "print(\"F-1 score is\", f1_score(y, dtree.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Random Forest\n",
    "Random Forests are an ensemble learning method that fit multiple Decision Trees on subsets of the data and average the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "RF.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy and F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy is\", RF.score(X,y))\n",
    "print(\"F-1 score is\", f1_score(y, RF.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Support Vector Machines\n",
    "Support Vector Machines (SVMs) are a type of classification algorithm that are more flexible - they can do linear classification, but can use other non-linear basis functions. The following example uses a linear classifier to fit a hyperplane that separates the data into two classes. To apply SVM, you may call `LinearSVC` or `SVC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = sk.svm.SVC(kernel='linear')\n",
    "SVM.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy and F-1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy is\", SVM.score(X,y))\n",
    "print(\"F-1 score is\", f1_score(y, SVM.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Neural Networks\n",
    "Neural Networks are a machine learning algorithm that involves fitting many hidden layers used to represent neurons that are connected with synaptic activation functions. These essentially use a very simplified model of the brain to model and predict data.\n",
    "\n",
    "One can use `sklearn` library for neural networks, however libraries such as `Tensorflow` and `Keras` are more suited to fitting and customizing neural networks. We will try these libraries next week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "NN.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy and F-1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy is\", NN.score(X,y))\n",
    "print(\"F-1 score is\", f1_score(y, NN.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Naive Bayes\n",
    "\n",
    "Naive Bayes algorithm based on Bayes’ theorem with the assumption of independence between every pair of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy and F-1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy is\", nb.score(X,y))\n",
    "print(\"F-1 score is\", f1_score(y, nb.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other classifiers\n",
    "\n",
    "**8. Stochastic Gradient Descent**\n",
    "\n",
    "Stochastic gradient descent is a simple and very efficient approach to fit linear models. It is particularly useful when the number of samples is very large. It supports different loss functions and penalties for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier(loss='modified_huber', shuffle=True, random_state=101)\n",
    "sgd.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy and F-1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy is\", sgd.score(X,y))\n",
    "print(\"F-1 score is\", f1_score(y, sgd.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. XGBoost**\n",
    "\n",
    "XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. It is an implementation of the Gradient Boosted Decision Trees algorithm. **The idea** is that it go through cycles that repeatedly builds new models and combines them into an ensemble model. XGBoost models dominate many Kaggle competitions.\n",
    "\n",
    "More information is available [here](https://www.kaggle.com/dansbecker/xgboost)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy and F-1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy is\", xgb.score(X,y))\n",
    "print(\"F-1 score is\", f1_score(y, xgb.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. Linear Discriminant Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy and F-1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy is\", lda.score(X,y))\n",
    "print(\"F-1 score is\", f1_score(y, lda.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [[precision_score(y, LR.predict(X)), recall_score(y, LR.predict(X)), LR.score(X,y), f1_score(y, LR.predict(X))],\n",
    "           [precision_score(y, knn.predict(X)), recall_score(y, knn.predict(X)), knn.score(X,y), f1_score(y, knn.predict(X))],\n",
    "           [precision_score(y, dtree.predict(X)), recall_score(y, dtree.predict(X)), dtree.score(X,y), f1_score(y, dtree.predict(X))],\n",
    "           [precision_score(y, RF.predict(X)), recall_score(y, RF.predict(X)), RF.score(X,y), f1_score(y, RF.predict(X))],\n",
    "           [precision_score(y, SVM.predict(X)), recall_score(y, SVM.predict(X)), SVM.score(X,y), f1_score(y, SVM.predict(X))],\n",
    "           [precision_score(y, NN.predict(X)), recall_score(y, NN.predict(X)), NN.score(X,y), f1_score(y, NN.predict(X))],\n",
    "           [precision_score(y, nb.predict(X)), recall_score(y, nb.predict(X)), nb.score(X,y), f1_score(y, nb.predict(X))],\n",
    "           [precision_score(y, sgd.predict(X)), recall_score(y, sgd.predict(X)), sgd.score(X,y), f1_score(y, sgd.predict(X))],\n",
    "           [precision_score(y, xgb.predict(X)), recall_score(y, xgb.predict(X)), xgb.score(X,y), f1_score(y, xgb.predict(X))],\n",
    "           [precision_score(y, lda.predict(X)), recall_score(y, lda.predict(X)), lda.score(X,y), f1_score(y, lda.predict(X))]]\n",
    "\n",
    "df = pd.DataFrame(data=results, \n",
    "                  index=[\"Logistic Regression\", \"K-Nearest Neighbours\", \"Decision Tree\", \"Random Forest\",\n",
    "                        \"SVM\", \"Neural Networks\", \"Naive Bayes\", \"SGD\", \"XGBoost\", \"Linear Discriminant Analysis\"], \n",
    "                  columns=[\"Precision\", \"Recall\", \"Accuracy\", \"F1-score\"])\n",
    "df['label'] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_point(x, y, val, ax):\n",
    "    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n",
    "    for i, point in a.iterrows():\n",
    "        ax.text(point['x'], point['y'], str(point['val']))\n",
    "\n",
    "        \n",
    "def drawScatter(df, col1, col2, label=\"label\"):\n",
    "    plt.style.use(\"fivethirtyeight\")\n",
    "    fig = plt.figure(figsize = (8,8))\n",
    "    ax = fig.gca()\n",
    "    label_point(df[col1], df[col2], df.label, ax)\n",
    "    df.plot.scatter(x=col1, y=col2, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawScatter(df, 'Precision', 'Recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawScatter(df, 'Accuracy', 'F1-score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class Classification\n",
    "Let us consider the fruits dataset (fruit_data_with_colors.txt) which contains a few dozen oranges, lemons and apples of different varieties and their measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits = pd.read_table('fruit_data_with_colors.txt')\n",
    "fruits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 59 pieces of fruits and 7 features in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fruits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fruits.groupby('fruit_name').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(fruits['fruit_name'],label=\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our data is more or less balanced, thus, no additional techniques are required.\n",
    "\n",
    "Let us draw some histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,10))\n",
    "ax = fig.gca()\n",
    "fruits.hist(ax = ax, bins=30)\n",
    "plt.suptitle('List of histograms', x=0.5, y=1, ha='center', fontsize='xx-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some pairs of attributes are correlated (mass and width). This suggests a high correlation and a predictable relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the numerical values do not have the same scale. We will need to apply scaling to the test set that we computed for the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training and Test Sets and Apply Scaling\n",
    "\n",
    "The split of the dataset is performed using the `train_test_split` methods which is a part of `sklearn` package. By default, the data is divided into 2 parts: training set (75%) and test set (25%). However, it is also possible to set the size of the dataset (e.g., input parameter `test_size=0.3` which corresponds to 30% splitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = fruits.iloc[:,0]\n",
    "X = fruits.iloc[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let us rescale our data.\n",
    "`MinMaxScaler` estimator scales and translates each feature individually such that it is in the given range on the training set, e.g. between zero and one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Models\n",
    "\n",
    "We use the training set to learn the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. LR\n",
    "LR = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr', max_iter=1000)\n",
    "LR.fit(X_train, y_train)\n",
    "\n",
    "#2. knn\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#3. Desicion tree\n",
    "dtree = DecisionTreeClassifier(max_depth = 5, random_state = 101, min_samples_leaf = 5)\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "#4. Random Forest\n",
    "RF = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "RF.fit(X_train, y_train)\n",
    "\n",
    "#5. SVM\n",
    "SVM = sk.svm.SVC(kernel='linear')\n",
    "SVM.fit(X_train, y_train)\n",
    "\n",
    "#7. Naive Bayes\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "#8. SGD\n",
    "sgd = SGDClassifier(loss='modified_huber', shuffle=True, random_state=101)\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "#9. XGBoost\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "#10. LDA\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of LR classifier', LR.score(X_test,y_test))\n",
    "print('Accuracy of KNN classifier', knn.score(X_test,y_test))\n",
    "print('Accuracy of Desicion tree classifier', dtree.score(X_test,y_test))\n",
    "print('Accuracy of Random Forest classifier', RF.score(X_test,y_test))\n",
    "print('Accuracy of SVM classifier', SVM.score(X_test,y_test))\n",
    "print('Accuracy of Naive Bayes classifier', nb.score(X_test,y_test))\n",
    "print('Accuracy of SGD classifier', sgd.score(X_test,y_test))\n",
    "print('Accuracy of XGBoost classifier', xgb.score(X_test,y_test))\n",
    "print('Accuracy of LDA classifier', lda.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN algorithm was the most accurate model that we tried. The confusion matrix provides an indication of no error made on the test set. However, the test set was very small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = knn.predict(X_test)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can also construct the confusion matrix and classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional: Define the optimal number of neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = range(1, 20)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    scores.append(knn.score(X_test, y_test))\n",
    "plt.figure()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.scatter(k_range, scores)\n",
    "plt.xticks([0,5,10,15,20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity to the size of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "t = [0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for s in t:\n",
    "    scores = []\n",
    "    for i in range(1,1000):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1-s)\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        knn.fit(X_train, y_train)\n",
    "        scores.append(knn.score(X_test, y_test))\n",
    "    plt.plot(s, np.mean(scores), 'bo')\n",
    "\n",
    "plt.xlabel('Training set proportion (%)')\n",
    "plt.ylabel('accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional: Plot the Decision Boundary of the k-NN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "X = fruits[['mass', 'width', 'height', 'color_score']]\n",
    "y = fruits['fruit_label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "\n",
    "def plot_fruit_knn(X, y, n_neighbors, weights):\n",
    "    X_mat = X[['height', 'width']].values\n",
    "    y_mat = y.values\n",
    "# Create color maps\n",
    "    cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF','#AFAFAF'])\n",
    "    cmap_bold  = ListedColormap(['#FF0000', '#00FF00', '#0000FF','#AFAFAF'])\n",
    "    clf = KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "    clf.fit(X_mat, y_mat)\n",
    "# Plot the decision boundary by assigning a color in the color map\n",
    "    # to each mesh point.\n",
    "    \n",
    "    mesh_step_size = .01  # step size in the mesh\n",
    "    plot_symbol_size = 50\n",
    "    \n",
    "    x_min, x_max = X_mat[:, 0].min() - 1, X_mat[:, 0].max() + 1\n",
    "    y_min, y_max = X_mat[:, 1].min() - 1, X_mat[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, mesh_step_size),\n",
    "                         np.arange(y_min, y_max, mesh_step_size))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "# Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure()\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "# Plot training points\n",
    "    plt.scatter(X_mat[:, 0], X_mat[:, 1], s=plot_symbol_size, c=y, cmap=cmap_bold, edgecolor = 'black')\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    patch0 = mpatches.Patch(color='#FF0000', label='apple')\n",
    "    patch1 = mpatches.Patch(color='#00FF00', label='mandarin')\n",
    "    patch2 = mpatches.Patch(color='#0000FF', label='orange')\n",
    "    patch3 = mpatches.Patch(color='#AFAFAF', label='lemon')\n",
    "    plt.legend(handles=[patch0, patch1, patch2, patch3])\n",
    "    plt.xlabel('height (cm)')\n",
    "    plt.ylabel('width (cm)')\n",
    "    plt.title(\"4-Class classification (k = %i, weights = '%s')\"\n",
    "           % (n_neighbors, weights))    \n",
    "    plt.show()\n",
    "\n",
    "plot_fruit_knn(X_train[['height', 'width']], y_train, 5, 'uniform')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The k-fold cross-validation procedure is a standard method for estimating the performance of a machine learning algorithm or configuration on a dataset.\n",
    "\n",
    "A single run of the k-fold cross-validation procedure may result in a noisy estimate of model performance. Different splits of the data may result in very different results.\n",
    "\n",
    "Repeated k-fold cross-validation provides a way to improve the estimated performance of a machine learning model. This involves simply repeating the cross-validation procedure multiple times and reporting the mean result across all folds from all runs. This mean result is expected to be a more accurate estimate of the true unknown underlying mean performance of the model on the dataset, as calculated using the standard error.\n",
    "\n",
    "#### Step 1. Create/Load Dataset\n",
    "Let us apply k-fold cross-validation procedure to a synthetic classification dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20) (1000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2. Set the parameter k\n",
    "\n",
    "Assume k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3. Define the model\n",
    "Consider the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4. Perform cross-validation and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "y_pred = cross_val_predict(model, X, y, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.868 (0.032)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return the scores for each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89, 0.82, 0.92, 0.88, 0.91, 0.82, 0.86, 0.86, 0.85, 0.87])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Manual cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize cross-validation and define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make manual iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.DataFrame(y)\n",
    "for i in range(10):\n",
    "    result = next(cv.split(X), None)\n",
    "    x_train = X.iloc[result[0]]\n",
    "    x_test = X.iloc[result[1]]\n",
    "    y_train = y.iloc[result[0]]\n",
    "    y_test = y.iloc[result[1]]\n",
    "    model = model.fit(x_train, y_train.values.ravel())\n",
    "    #predictions = model.predict(x_test)\n",
    "    scores.append(model.score(x_test, y_test))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeated Cross-Validation\n",
    "\n",
    "The estimate of model performance via k-fold cross-validation can be noisy.\n",
    "\n",
    "This means that each time the procedure is run, a different split of the dataset into k-folds can be implemented, and in turn, the distribution of performance scores can be different, resulting in a different mean estimate of model performance.\n",
    "\n",
    "One solution to reduce the noise in the estimated model performance is to increase the k-value. This will reduce the bias in the model’s estimated performance, although it will increase the variance: e.g. tie the result more to the specific dataset used in the evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `scikit-learn` Python machine learning library provides an implementation of repeated k-fold cross-validation via the `RepeatedKFold` class.\n",
    "\n",
    "The main parameters are the number of folds (n_splits), which is the “k” in k-fold cross-validation, and the number of repeats (n_repeats).\n",
    "\n",
    "A good default for k is k=10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "cvR = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cvR, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main results about cross-validation\n",
    "- The mean performance reported from a single run of k-fold cross-validation may be noisy.\n",
    "- Repeated k-fold cross-validation provides a way to reduce the error in the estimate of mean model performance.\n",
    "- How to evaluate machine learning models using repeated k-fold cross-validation in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalanced Data\n",
    "\n",
    "Imbalanced classes is a surprisingly common problem in machine learning (specifically in classification), occurring in datasets with a disproportionate ratio of observations in each class.\n",
    "\n",
    "**Standard accuracy no longer reliably measures performance, which makes model training much trickier.**\n",
    "\n",
    "Imbalanced classes appear in many domains, including:\n",
    "\n",
    "- Fraud detection\n",
    "- Spam filtering\n",
    "- Disease screening\n",
    "- SaaS subscription churn\n",
    "- Advertising click-throughs\n",
    "\n",
    "Thus, there is a need to explore **effective ways** to handle imbalanced classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us use a synthetic dataset called *Balance Scale Data* (available at UCI Machine Learning Repository). The dataset contains information about whether a scale is balanced or not, based on weights and distances of the two arms.\n",
    "![Balance Scale Data](https://elitedatascience.com/wp-content/uploads/2017/06/balance-scale-data.png \"Balance Scale Data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('balance-scale.data', \n",
    "                 names=['balance', 'var1', 'var2', 'var3', 'var4'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable has 3 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['balance'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume, we turn the data this into **a binary classification problem**. We're going to label each observation as 1 (positive class) if the scale is balanced or 0 (negative class) if the scale is not balanced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['balance'] = [1 if b=='B' else 0 for b in df.balance]\n",
    "df['balance'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, only about 8% of the observations were balanced. Therefore, **if we were to always predict 0, we'd achieve an accuracy of 92%.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Danger of Imbalanced Classes\n",
    "Let us apply the Logistic Regression algorithm to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.balance\n",
    "X = df.drop('balance', axis=1)\n",
    "\n",
    "LR = LogisticRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now make the prediction and evaluate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_0 = LR.predict(X)\n",
    "print(accuracy_score(pred_y_0, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our model has 92% overall accuracy, but is it because it's predicting only 1 class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this model is only predicting 0, which means it's completely ignoring the minority class in favor of the majority class.\n",
    "\n",
    "Next, we'll look at **some techniques for handling imbalanced classes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Resampling Techniques](https://miro.medium.com/max/725/1*H6XodlitlGDl9YdbwaZLMw.png \"Resampling Techniques\")\n",
    "\n",
    "\n",
    "\n",
    "## 1. Up-sample Minority Class\n",
    "\n",
    "Up-sampling is the process of randomly duplicating observations from the minority class in order to reinforce its signal.\n",
    "\n",
    "\n",
    "There are several heuristics for doing so, but the most common way is to simply resample with replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = df[df.balance==0]\n",
    "df_minority = df[df.balance==1]\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=df_majority.shape[0],    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "df_upsampled.balance.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now apply the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate input features (X) and target variable (y)\n",
    "y = df_upsampled.balance\n",
    "X = df_upsampled.drop('balance', axis=1)\n",
    "\n",
    "# Train model\n",
    "LR1 = LogisticRegression().fit(X, y)\n",
    " \n",
    "# Predict on training set\n",
    "pred_y_1 = LR1.predict(X)\n",
    " \n",
    "# Is our model still predicting just one class?\n",
    "print(np.unique( pred_y_1 ))\n",
    "# [0 1]\n",
    " \n",
    "# How's our accuracy?\n",
    "print( accuracy_score(y, pred_y_1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now the model is no longer predicting just one class. While the accuracy also took a nosedive, it's now more meaningful as a performance metric.\n",
    "\n",
    "## 2. Down-sample Majority Class\n",
    "\n",
    "Down-sampling involves randomly removing observations from the majority class to prevent its signal from dominating the learning algorithm.\n",
    "\n",
    "The most common heuristic for doing so is resampling without replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate majority and minority classes\n",
    "df_majority = df[df.balance==0]\n",
    "df_minority = df[df.balance==1]\n",
    " \n",
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=49,     # to match minority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine minority class with downsampled majority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    " \n",
    "# Display new class counts\n",
    "df_downsampled.balance.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now apply the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate input features (X) and target variable (y)\n",
    "y = df_downsampled.balance\n",
    "X = df_downsampled.drop('balance', axis=1)\n",
    " \n",
    "# Train model\n",
    "LR2 = LogisticRegression().fit(X, y)\n",
    " \n",
    "# Predict on training set\n",
    "pred_y_2 = LR2.predict(X)\n",
    " \n",
    "# Is our model still predicting just one class?\n",
    "print(np.unique(pred_y_2))\n",
    " \n",
    "# How's our accuracy?\n",
    "print(accuracy_score(y, pred_y_2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model isn't predicting just one class, and the accuracy seems higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Change Your Performance Metric\n",
    "\n",
    "For a general-purpose metric for classification, we recommend Area Under ROC Curve (AUROC). Intuitively, AUROC represents the likelihood of your model distinguishing observations from two classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class probabilities\n",
    "prob_y_2 = LR2.predict_proba(X)\n",
    "\n",
    "# Keep only the positive class\n",
    "prob_y_2 = [p[1] for p in prob_y_2]\n",
    "\n",
    "prob_y_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roc_auc_score(y, prob_y_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us compare to the original model trained on the imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_y_0 = LR.predict_proba(X)\n",
    "prob_y_0 = [p[0] for p in prob_y_0] # AUROC should be >= 0.5. If you got <0.5, you should change p[0] to p[1]\n",
    " \n",
    "print(roc_auc_score(y, prob_y_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We can observe that AUROC is higher for LR2 (Down-sampling) compared to the initial model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Use Penalize Algorithms (Cost-Sensitive Training)\n",
    "\n",
    "The next tactic is to use penalized learning algorithms that increase the cost of classification mistakes on the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "y = df.balance\n",
    "X = df.drop('balance', axis=1)\n",
    " \n",
    "# Train model\n",
    "model3 = SVC(kernel='linear', \n",
    "            class_weight='balanced', # penalize proportianally to the size of the classes\n",
    "            probability=True)\n",
    " \n",
    "model3.fit(X, y)\n",
    " \n",
    "# Predict on training set\n",
    "pred_y_3 = model3.predict(X)\n",
    " \n",
    "# Is our model still predicting just one class?\n",
    "print(\"Predicted classes\", np.unique( pred_y_3 ))\n",
    "\n",
    "# How's our accuracy?\n",
    "print(\"Accuracy\", accuracy_score(y, pred_y_3))\n",
    "\n",
    "# What about AUROC?\n",
    "prob_y_3 = model3.predict_proba(X)\n",
    "prob_y_3 = [p[0] for p in prob_y_3]\n",
    "print(\"AUROC is\",roc_auc_score(y, prob_y_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Use Tree-Based Algorithms\n",
    "The final tactic we'll consider is using tree-based algorithms. Decision trees often perform well on imbalanced datasets because their hierarchical structure allows them to learn signals from both classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.balance\n",
    "X = df.drop('balance', axis=1)\n",
    " \n",
    "# Train model\n",
    "model4 = RandomForestClassifier()\n",
    "model4.fit(X, y)\n",
    " \n",
    "# Predict on training set\n",
    "pred_y_4 = model4.predict(X)\n",
    " \n",
    "# Is our model still predicting just one class?\n",
    "print(\"Predicted classes\", np.unique(pred_y_4 ))\n",
    " \n",
    "# How's our accuracy?\n",
    "print(\"Accuracy\", accuracy_score(y, pred_y_4))\n",
    "# 0.9744\n",
    " \n",
    "# What about AUROC?\n",
    "prob_y_4 = model4.predict_proba(X)\n",
    "prob_y_4 = [p[1] for p in prob_y_4]\n",
    "print(\"AUROC is\", roc_auc_score(y, prob_y_4) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, tree ensembles have become very popular because they perform extremely well on many real-world problems. We certainly recommend them wholeheartedly.\n",
    "\n",
    "**However:**\n",
    "\n",
    "While these results are encouraging, the model could be **overfit**, so you should still evaluate your model on an unseen test set before making the final decision."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
